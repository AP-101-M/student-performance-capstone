{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11e18cdb",
   "metadata": {},
   "source": [
    "# ðŸŽ“ Capstone Project: Predicting Student Performance Using Machine Learning\n",
    "\n",
    "---\n",
    "\n",
    "**Submitted for:** CACIITG Summer Analytics 2025\n",
    "\n",
    "**Objective:** Predict whether a student will pass or fail based on various demographic and academic features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41a2156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“¦ Step 1: Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4937eb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“¥ Step 2: Load Dataset\n",
    "df = pd.read_csv('StudentsPerformance.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4711374e",
   "metadata": {},
   "source": [
    "##  Step 3: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8080b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values and data types\n",
    "df.info()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acba9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of scores\n",
    "sns.histplot(df['math score'], kde=True)\n",
    "plt.title('Distribution of Math Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f0f623",
   "metadata": {},
   "source": [
    "##  Step 4: Data Preprocessing\n",
    "- Convert scores to binary classification: **Pass (>=40)** or **Fail (<40)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b450572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'overall_score' and pass/fail label\n",
    "df['average'] = (df['math score'] + df['reading score'] + df['writing score']) / 3\n",
    "df['result'] = df['average'].apply(lambda x: 1 if x >= 40 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f21f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical columns\n",
    "label_cols = ['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course']\n",
    "le = LabelEncoder()\n",
    "for col in label_cols:\n",
    "    df[col] = le.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4c7d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target\n",
    "X = df.drop(['math score', 'reading score', 'writing score', 'average', 'result'], axis=1)\n",
    "y = df['result']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b27607",
   "metadata": {},
   "source": [
    "## Step 5: Model Building & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7b1907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1392db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa9ebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ef31c3",
   "metadata": {},
   "source": [
    "##  Conclusion:\n",
    "- **Random Forest** gave the best accuracy on this dataset.\n",
    "- Features like **test preparation course** and **parental education** were significant.\n",
    "- This model can be used to guide academic interventions.\n",
    "\n",
    "---\n",
    "**Thanks to CACIITG for this enriching learning journey!** ðŸŽ‰"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
